# ğŸ“ Technical Architecture

Deep technical documentation for developers extending or debugging the voice assistant.

## ğŸ—ï¸ System Architecture

The application implements a classic pipeline architecture with three independent subsystems:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio In   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STT Pipeline       â”‚
â”‚ (Audio â†’ Text)       â”‚
â”‚ â€¢ Record audio       â”‚
â”‚ â€¢ Transcribe via     â”‚
â”‚   whisper.cpp        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Pipeline        â”‚
â”‚ (Text â†’ Response)    â”‚
â”‚ â€¢ Ollama Chat API    â”‚
â”‚ â€¢ Gemma 3.x model    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TTS Pipeline       â”‚
â”‚ (Text â†’ Audio)       â”‚
â”‚ â€¢ Synthesize via     â”‚
â”‚   piper-tts          â”‚
â”‚ â€¢ Playback with rodioâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio Out   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Modules

#### `assistant` Module
**Responsibility**: Orchestration and conversation management

- **`conversation.rs`** â€” Main event loop
  - `run()`: Drives the interaction cycle
  - `listen_to_user()`: Records and transcribes user input
  - `speak_response()`: Synthesizes and plays LLM response
  - Maintains `conversation_history: Vec<Message>`

- **`llm.rs`** â€” Ollama integration
  - `chat_with_ollama()`: Calls the Ollama Chat API
  - Structures messages in OpenAI-compatible format
  - Handles HTTP errors with detailed context

#### `stt` Module
**Responsibility**: Speech-to-text pipeline

- **`audio.rs`** â€” Device detection
  - `get_default_input_device()`: Queries system for the default microphone
  - Handles platform-specific audio subsystem APIs via `cpal`

- **`recorder.rs`** â€” Audio capture
  - `record_audio()`: Captures PCM samples to WAV using `hound`
  - Supports `I16` and `F32` sample formats
  - Returns `Result<(), anyhow::Error>`

- **`transcriber.rs`** â€” Whisper integration
  - `transcribe_with_whisper()`: Spawns the whisper.cpp CLI
  - Parses the generated `.txt` output file
  - Locates the binary across OS variants (macOS, Linux, Windows)

#### `tts` Module
**Responsibility**: Text-to-speech pipeline

- **`engine.rs`** â€” Piper synthesis & playback
  - `synthesize()`: Spawns piper-tts subprocess
  - `play_audio()`: Uses `rodio` for system audio output
  - Captures stderr for detailed error reporting

- **`voice.rs`** â€” Voice catalog
  - `voices()`: Registry of available speaker models
  - Currently: `en_GB-cori-high` (UK English, female, high quality)
  - Extensible for additional voices

- **`models.rs`** â€” Model caching & downloads
  - Downloads ONNX models on first run
  - Caches to `./models/` directory
  - Verifies file integrity before use

## ğŸ”„ Data Flow

### Request-Response Cycle

```
User Input
    â†“
[1] Record Audio (cpal/hound)
    â†“
user_input.wav
    â†“
[2] Transcribe (whisper.cpp CLI)
    â†“
user_input.wav.txt
    â†“
[3] Chat Request (Ollama HTTP API)
    â”œâ”€ model: "gemma3"
    â”œâ”€ messages: [system, history, user]
    â””â”€ stream: false
    â†“
[4] LLM Response (Gemma 3.x)
    â”œâ”€ role: "assistant"
    â””â”€ content: "Natural language response"
    â†“
[5] Synthesize (piper-tts subprocess)
    â”œâ”€ input: response text
    â””â”€ output: assistant_response.wav
    â†“
[6] Playback (rodio)
    â†“
Audio Output
```

## ğŸŒ API Integration

### Ollama Chat API

**Endpoint**: `POST http://localhost:11434/api/chat`

**Request Format** (OpenAI-compatible):
```json
{
  "model": "gemma3",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "What is Rust?"
    }
  ],
  "stream": false
}
```

**Response Format**:
```json
{
  "model": "gemma3",
  "created_at": "2024-12-01T10:30:45.123Z",
  "message": {
    "role": "assistant",
    "content": "Rust is a systems programming language..."
  },
  "done": true,
  "total_duration": 5000000000,
  "load_duration": 1000000000,
  "prompt_eval_count": 15,
  "prompt_eval_duration": 2000000000,
  "eval_count": 120,
  "eval_duration": 2000000000
}
```

**Error Handling**:
- Non-2xx HTTP status codes trigger detailed error messages
- Response body is included in error context
- Network timeouts handled via `tokio::timeout`

## ğŸ’¾ State Management

### Memory Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Assistant Runtime State               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  conversation_history: Vec<Message>    â”‚
â”‚  â”œâ”€ { role: "user", content: "..." }   â”‚
â”‚  â”œâ”€ { role: "assistant", content: "..." }
â”‚  â””â”€ ...                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Current Message Buffers               â”‚
â”‚  â”œâ”€ user_input.wav (audio file)        â”‚
â”‚  â”œâ”€ user_input.wav.txt (transcript)    â”‚
â”‚  â”œâ”€ assistant_response.wav (audio)     â”‚
â”‚  â””â”€ Generated at runtime               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cached Models                         â”‚
â”‚  â”œâ”€ ./models/ggml-base.en.bin          â”‚
â”‚  â”œâ”€ ./models/en_GB-cori-high.onnx      â”‚
â”‚  â”œâ”€ ./models/en_GB-cori-high.onnx.json â”‚
â”‚  â””â”€ Downloaded on first use            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conversation History

Maintained as a `Vec<Message>` in memory:
```rust
pub struct Message {
    pub role: String,    // "user" or "assistant"
    pub content: String, // The actual text
}
```

Each interaction appends two messages (user + assistant) to the history. The entire history is sent to Ollama for contextual understanding.

## âš¡ Performance Characteristics

| Operation | Typical Duration | Bottleneck |
|-----------|-----------------|-----------|
| Audio Recording (5 seconds) | 5s | User timing |
| Whisper Transcription | 2-5s | Model inference (CPU-bound) |
| Ollama Chat Request | 1-10s | Model generation speed |
| Piper TTS Synthesis | 0.5-2s | Model inference |
| rodio Playback | Variable | Audio stream duration |
| **Total Round-trip** | **10-30s** | Inference speed |

**Optimization Opportunities**:
- Streaming STT to start transcription before recording completes
- Streaming TTS to begin playback before full synthesis finishes
- Quantized models for faster inference
- GPU acceleration for Ollama and Whisper

## ğŸ› ï¸ Error Handling Strategy

The project uses `anyhow` for ergonomic error handling with context:

### Error Propagation Pattern
```rust
// Example from transcriber.rs
let output = Command::new(whisper_bin)
    .args(&[...])
    .output()
    .context("failed to execute whisper")?;

if !output.status.success() {
    anyhow::bail!(
        "whisper failed: {}",
        String::from_utf8_lossy(&output.stderr)
    );
}
```

### Error Sources by Module

| Module | Common Errors | Recovery |
|--------|--------------|----------|
| `recorder` | No input device, format unsupported | Bail with helpful message |
| `transcriber` | Binary not found, model missing | Bail with path suggestions |
| `llm` | Ollama unreachable, HTTP error | Bail with endpoint hint |
| `engine` | Piper not in PATH, synthesis failed | Bail with stderr context |

## ğŸ” Security Considerations

1. **No External Calls**: All processing is local; no telemetry or cloud API calls
2. **File Permissions**: Audio files are world-readable by default (consider restrictive umask)
3. **Model Integrity**: No checksum verification of downloaded models
4. **Subprocess Spawning**: Piper and Whisper are executed via `std::process::Command` without shell=true (safe)

## ğŸ“Š Sequence Diagram

```
User    â†’  Recorder  â†’  Whisper  â†’  Assistant  â†’  Ollama  â†’  Piper  â†’  Speaker
 â”‚           â”‚           â”‚           â”‚            â”‚         â”‚        â”‚
 â”œâ”€Speakâ”€â”€â”€â”€â”€â†’           â”‚           â”‚            â”‚         â”‚        â”‚
 â”‚           â”œâ”€Recordâ”€â”€â”€â”€â†’           â”‚            â”‚         â”‚        â”‚
 â”‚           â”‚   (WAV)   â”‚           â”‚            â”‚         â”‚        â”‚
 â”‚           â”‚           â”œâ”€Transcribeâ”‚            â”‚         â”‚        â”‚
 â”‚           â”‚           â”‚ (TXT)     â”‚            â”‚         â”‚        â”‚
 â”‚           â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’            â”‚         â”‚        â”‚
 â”‚           â”‚           â”‚           â”œâ”€POST chatâ”€â†’         â”‚        â”‚
 â”‚           â”‚           â”‚           â”‚            â”œâ”€Responseâ†’        â”‚
 â”‚           â”‚           â”‚           â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚        â”‚
 â”‚           â”‚           â”‚           â”œâ”€Synthesizeâ”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚        â”‚
 â”‚           â”‚           â”‚           â”‚            â”‚  (WAV)  â”‚        â”‚
 â”‚           â”‚           â”‚           â”‚            â”‚         â”œâ”€Playâ”€â”€â†’
 â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 â”‚                       Audio Response                               â”‚
```

## ğŸ§ª Testing Approach

The project currently relies on manual testing. Recommended automated test structure:

```rust
#[cfg(test)]
mod tests {
    #[test]
    fn test_transcriber_with_fixture() {
        // Transcribe a known WAV file
        let text = transcribe_with_whisper("./test_audio.wav");
        assert!(text.contains("expected text"));
    }

    #[test]
    fn test_ollama_mock() {
        // Replace reqwest with mock HTTP response
        let response = chat_with_ollama(&messages);
        assert_eq!(response.message.role, "assistant");
    }

    #[test]
    fn test_piper_synthesis() {
        // Verify .wav file is created and valid
        synthesize("Hello world");
        assert!(Path::new("assistant_response.wav").exists());
    }
}
```

## ğŸ”— Navigation

- [Overview](./README.md) â€” Project introduction
- [Installation](./installation.md) â€” Setup guide
- [Development](./development.md) â€” Contributing
- [Troubleshooting](./troubleshooting.md) â€” Problem solving
- [FAQ](./faq.md) â€” Common questions
- [Roadmap](./roadmap.md) â€” Future plans
- [Known Issues](./known-issues.md) â€” Current limitations

---

**Last Updated**: December 2025